[TOC]

# 自定义Catalyst规则

**Catalyst规则 Catalyst规则分类：**

- 分析规则
  一般在 org.apache.spark.sql.catalyst.analysis
  继承 Rule[LogicalPlan]
- 优化规则
  一般在 org.apache.spark.sql.catalyst.optimizer
  继承 Rule[LogicalPlan]
- 策略规则
  一般在 org.apache.spark.sql.execution
  继承 Rule[SparkPlan]

**定制化规则**
增加和修改Catalyst规则需要修改源码，但有时候我们需要定制化一些临时或者和业务有关的规则。

![082.CustomizedRules](04Modulepics/082.CustomizedRules.png)

scala继承 (SparkSessionExtensions => Unit)
java继承 Function1[SparkSessionExtensions, Unit]
参数指定 spark.sql.extensions

**规则注入**

![083.RuleInjection](04Modulepics/083.RuleInjection.png)

**例子：delta-lake**

![084.delta-lake](04Modulepics/084.delta-lake.png)

## 练习：实现自定义优化规则

第一步 实现自定义规则：

```scala
case class MyPushDown(spark: SparkSession) extends Rule[LogicalPlan] {
    def apply(plan: LogicalPlan): LogicalPlan = plan transform { …. }
}
```

第二步 创建自己的Extension并注入

```scala
class MySparkSessionExtension extends (SparkSessionExtensions => Unit) {
    override def apply(extensions: SparkSessionExtensions): Unit = {
        extensions.injectOptimizerRule { session =>
            new MyPushDown(session)
        }
    }
}
```


第三步 通过spark.sql.extensions提交

```
bin/spark-sql --jars my.jar --conf spark.sql.extensions=com.jikeshijian.MySparkSessionExtension
```

# 代码生成技术

## Tungsten项目
- 致力于提升Spark程序对内存和CPU的利用率，使性能达到硬件的极限，主要工作包含以下三个方面：

1. 内存管理和二进制数据编码：off-heap管理内存，降低对象的开销和消除JVM GC带来的延时。
2. 向量化，缓存感知计算：优化存储，提升CPU L1/ L2/L3缓存命中率。
3. 代码生成计算：优化Spark SQL的代码生成部分，提升CPU利用率。

**Tungsten内存管理和数据编码**
在相当多的场景中IO经常作为大数据开发的瓶颈，我们批处理,基于列存储,分区甚至是倒排索引,这一切的努力都是在解决磁盘的IO瓶颈。但是如果数据完全放入了内存之后,我们面临的新问题是什么呢?CPU不够用。

对于大数据的场景，其实我们没有把CPU的资源用在刀刃上，面对海量数据，**CPU第一件事情就是序列化与反序列化和压缩与解压数据**。在Spark这样的分布式计算模型下，需要大量的数据shuffle，必然需要将Java对象在不同的进程和机器间挪动。

CPU的**第二件事情就是创建对象**，在海量数据情况下，CPU需要把海量对象写回到内存中。

CPU的**第三件事情就是Java垃圾回收**了。

**Tungsten数据编码**

![085.TunstenDataEncoding](04Modulepics/085.TunstenDataEncoding.png)

![086.TunstenDataEncoding](04Modulepics/086.TunstenDataEncoding.png)

**Tungsten序列化性能**

![087.TunstenSerialization](04Modulepics/087.TunstenSerialization.png)

**Tungsten计划**

单行所用时间 (纳秒, 单线程)

![088.TungstenPlan](04Modulepics/088.TungstenPlan.png)

**Tungsten代码生成**

- 代码生成其实是数据库领域的通用技术之一。
- 代码生成往往用在代码不好写或者改写复杂的系统中。
- 动态代码生成方式有很多，例如JavaCompiler和Janino等等。

**为什么需要代码生成**

- 在Apache Spark 2.0之前，Spark SQL的底层实现是基于Volcano Iterator Model。
- 当今绝大多数数据库系统处理SQL在底层都是基于这个模型的。
- 这个模型的执行可以概括为：
  - 首先数据库引擎会将SQL翻译成一系列的关系代数算子或表达式；
  - 然后依赖这些关系代数算子逐条处理输入数据并产生结果。
  - 每个算子在底层都实现同样的接口，比如都实现了 next() 方法，然后最顶层的算子 next() 调用子
  - 算子的 next()，子算子的 next() 在调用孙算子的 next()，直到最底层的 next()。

![089.CodeGeneration](04Modulepics/089.CodeGeneration.png)

**preparations**

![090.preparations](04Modulepics/090.preparations.png)

**Volcano Iterator Model**

http://paperhub.s3.amazonaws.com/dace52a42c07f7f8348b08dc2b186061.pdf

![091.Volcano](04Modulepics/091.Volcano.png)

**火山模型的优缺点**

- 优点是抽象起来很简单，很容易实现。
- 缺点是存在大量的虚函数调用，会引起CPU的中断，最终影响了执行效率

![092.volcano](04Modulepics/092.volcano.png)

**火山模型 vs 手写代码**

- 火山模型

```scala
class Filter {
    def next(): Boolean = {
        var found = false
        while (!found && child.next()) {
            found = predicate(child.fetch())
        }
        return found
    }
    def fetch(): InternalRow = {
        child.fetch()
    }
    ...
}
```

- 手写代码

```scala
long count = 0;
for (ss_item_sk in store_sales) {
    if (ss_item_sk == 1000) {
        count += 1;
    }
}
```

![093.VolcanoModel](04Modulepics/093.VolcanoModel.png)

## Codegen

![094.Codegen](04Modulepics/094.Codegen.png)

- 通过引入全阶段代码生成，大大减少了虚函数的调用，减少了CPU的调用，使得SQL的执行速度有很大提升。
- Spark使用Janino*将生成的代码进行编译然后加载到同一个JVM中去。
- 相比Volcano Iterator Model，全阶段代码生成的执行过程如下。

![095.Codegen](04Modulepics/095.Codegen.png)

**拓展*Janino**
Janino是一个超级小但又超级快的Java编译器。它不仅能像javac工具那样将一组源文件编译成字节码文件，还可以对一些Java表达式、代码块、类中的文本(class body)或者内存中源文件进行编译，并把编译后的字节码直接加载到同一个JVM中运行。
Janino不是一个开发工具，而是作为运行时的嵌入式编译器。

**Janino编译器实践**

![096.Janino](04Modulepics/096.Janino.png)

**核心接口和类**

- CodegenContext：
  代码生成的管理类
- CodegenSupport：
  继承该接口的算子必须实现produce()和consume()
- WholeStageCodegenExec：
  CodegenSupport的实现类之一，将同一个Stage所有继承CodegenSupport的算子进行合并，合并的逻辑封装到一个Wrapper类中，将其作为Janino编译时的输入参数。
- InputAdapter：
  胶水类，连接WholeStageCodegenExec和未实现CodegenSupport的算子。
- BufferedRowIterator：
  WholeStageCodegenExec生成的代码的父类，主要的成员函数为InternalRow next()和append(InternalRow row)

**算子的生产消费模型**
相邻的算子通过Produce-Consume模型进行代码生成。
Produce代码框架如下：

```java
if (!initialized) {
    // call child.produce()
    initialized = true;
}
while (hashmap.hasNext()) {
    row = hashmap.next();
    // call consume(), which will call parent.doConsume()
    if (shouldStop()) return;
}
```

Consume生成当前算子处理上游输入的Row的代码。
如Filter算子，生成的代码如下：

```java
if (!isNull1 && value2) {
    // call consume(), which will call parent.doConsume()
}
```

**consume/doConsume 和 produce/doProduce**
consume 和doConsume 用来“消费”，返回的是算子处理数据核心逻辑所对应生成的代码。
consume 方法会调用其父节点的 doConsume 方法。
produce/doProduce 则用来“生产”，返回的是该算子及其子节点所生成的代码。
produce 方法会调用 doProduce 方法。

**全阶段代码生成**
对于物理算子树中的不支持代码生成的节点时，CollapseCodegenStages规则会在其上插入一个名为InputAdapter的物理节点对其进行封装。

![097.AllStages](04Modulepics/097.AllStages.png)

**WholeStageCodegenExec**

- WholeStageCodegenExec是物理计划节点，所以其主要逻辑在execute()方法中。其execute方法具体分为数据获取与代码生成两部分。假设物理算子节点A支持代码生成，物理算子节点B不支持代码生成，因此B会采用InputAdapter封装。
- 数据的获取比较直接，调用inputRDDs递归得到整段代码的输入数据。
- 代码生成可以看作是两个方向相反的递归过程：代码的整体框架由produce/doProduce方法负责，父节点调用子节点；代码具体处理逻辑由consume/doConsume方法负责，由子节点调用父节点。

![098.WholeStageCodegenExec](04Modulepics/098.WholeStageCodegenExec.png)

**全阶段代码生成步骤**

![099.wholeStageCodegenExecStep](04Modulepics/099.wholeStageCodegenExecStep.png)

**练习：查看SQL生成的代码**

```
> explain codegen select a.customerId
from
(select customerId , amountPaid as amount from sales where 1 = '1'
) a
where amount=500.0;
```

# 向量化技术

**SIMD**
SIMD全称Single Instruction Multiple Data，单指令多数据流，即一条指令处理多条数据，是对CPU基本指令集对扩展。

![100.SIMD](04Modulepics/100.SIMD.png)

**Spark的向量读**
See VectorizedParquetRecordReader

![101.SparkVect](04Modulepics/101.SparkVect.png)

# SparkThriftserver

HiveServer2
HiveServer2通过ThriftCLIService监听服务器端口。
将请求转发给CLIService进行处理。最终请求传给OperationManager，OperationManager根据请求的类型创建一个具体的Operation进行处理。

![102.HiveServer2](04Modulepics/102.HiveServer2.png)

**SparkThriftServer2**
Spark Thrift Server最主要的区别是实现了自己的SQL Operation——SparkExecuteStatementOperation。其他例如创建表，删除表等请求处理完全复用HiveServer2的代码。

其外，对于Session的管理，实现了自己的SparkSQLSessionManager和SparkSQLOperationManager。

![103.SparkThriftServer2](04Modulepics/103.SparkThriftServer2.png)

**Spark Thriftserver流程**

![104.SparkThriftServerProcess](04Modulepics/104.SparkThriftServerProcess.png)

**Spark Thriftserver的项目实践**

- 使用Spark Thriftserver作为OLAP的服务
  - 用于即席查询
  - 多租户管理
  - doAs
  - Driver并行度优化
  - MemoryLeak修复
- 使用Spark Thriftserver作为DDL only服务
  - 用于ETL

# Spark的AQE和DPP加速

**Adaptive Query Execution**

- AQE的动机
  - 传统数据库和早期Spark：先构建“执行计划”再“执行”
  - 存在的问题：即便使用CBO技术，因为UDF、压缩率等因素的存在，Spark无法找出最佳的执行计划

- AQE的方案
  - 在“执行”的过程中不断构建新的“执行计划”

![105.aqe](04Modulepics/105.aqe.png)

## 缺少AQE时的挑战

- 如何设置Shuffle分区数（reducer个数）
- 1.P为设置的分区数：spark.sql.shuffle.partition（默认200）C为应用的并发总数：spark.executor.instances * spark.executor.cores一个Stage需要跑（P/C）轮才能跑完所有任务
- 2.如果Partition数设置的太小：造成并发度低，任务跑的慢，OOM
- 3.如果Partition数设置的太大：造成调度压力大，大量小文件，随机IO
- 4.同一个应用中Shuffle的数据量往往会逐渐减少，但Partition数在整个应用执行过程中不能改变

![106.aqe](04Modulepics/106.aqe.png)

- 如何选择Join算子类型
  - SELECT xxx FROM A JOIN B ON A.key1 = B.key2;

![107.lackaqe](04Modulepics/107.lackaqe.png)

- 默认的Broadcast阈值是10MB
- 对于复杂的查询，join会使用中间结果作为输入，此时Spark SQL无法获得准确的数据量，从而进行错误的估算。能进行BCJ的也被错误的执行成SMJ。

![108.lackaqe](04Modulepics/108.lackaqe.png)

- 数据倾斜的自动处理
  - 数据倾斜是Spark SQL性能杀手

![109.lackaqe](04Modulepics/109.lackaqe.png)

- 几种简单的处理办法
  - 增加Partition个数
  - 增加BCJ阈值
  - 找出倾斜的key并“加盐”

![110.lackaqeCompareAqe](04Modulepics/110.lackaqeCompareAqe.png)

![111.lackaqeCompareAqe](04Modulepics/111.lackaqeCompareAqe.png)

![112.lackaqeCompareAqe](04Modulepics/112.lackaqeCompareAqe.png)

![113.lackaqeCompareAqe](04Modulepics/113.lackaqeCompareAqe.png)

## AQE架构

![114.aqeArchitecture](04Modulepics/114.aqeArchitecture.png)

**AQE自动设置Reducer数**

![115.aqeReducer](04Modulepics/115.aqeReducer.png)

**AQE SMJ->BCJ**

![116.AQE-SMJ-BCJ](04Modulepics/116.AQE-SMJ-BCJ.png)

- 转成BCJ的收益：
  - Shuffle读：远程读，随机IO
  - Broadcast读：本地读，连续IO
  - SMJ容易造成数据倾斜

![117.AQE-SMJ-BCJ](04Modulepics/117.AQE-SMJ-BCJ.png)

**Skew join optimization**

- Partition 0中使用N个task代替1个task
- Join的结果再合并起来（A0-0 Join B0，A0-1 Join B0，…A0-N Join B0）

![118.SkewJoinOptimization](04Modulepics/118.SkewJoinOptimization.png)

## Dynamic Partition Pruning

时至今日，如何让查询再有100倍的提升？

![119.DynamicPartitionPruning](04Modulepics/119.DynamicPartitionPruning.png)

**Static Partition Pruning**

```sql
SELECT * FROM Sales WHERE day_of_week = ’Mon’;
```

![120.StaticPartitionPruning](04Modulepics/120.StaticPartitionPruning.png)

```sql
SELECT * FROM Sales Join Date WHERE Date.day_of_week = ’Mon’;
```

**Dynamic Partition Pruning**

![121.DynamicPartitionPruning](04Modulepics/121.DynamicPartitionPruning.png)

```sql
SELECT * FROM Sales Join Date WHERE Date.day_of_week = ’Mon’;
```

![122.DynamicPartitionPruning](04Modulepics/122.DynamicPartitionPruning.png)

![123.DynamicPartitionPruning](04Modulepics/123.DynamicPartitionPruning.png)

![124.DynamicPartitionPruning](04Modulepics/124.DynamicPartitionPruning.png)

![125.DynamicPartitionPruning](04Modulepics/125.DynamicPartitionPruning.png)

![126.DynamicPartitionPruning](04Modulepics/126.DynamicPartitionPruning.png)

![127.DynamicPartitionPruning](04Modulepics/127.DynamicPartitionPruning.png)

![128.DynamicPartitionPruning](04Modulepics/128.DynamicPartitionPruning.png)

通过维度条件在5年的数据中只使用1个月的数据进行join

非常适用于星型模型的查询

![129.DynamicPartitionPruning](04Modulepics/129.DynamicPartitionPruning.png)

# Spark SQL优化技术

## TeraData

目标

- 易于使用
- 查询性能
  - 匹配当前TD查询性能，总体性能无明显下降
- 易于调优，自适应优化
  - 能对错误的SQL和有问题的SQL进行优化
- 语法兼容
  - 语法层面减少迁移成本
  - 支持增删改查操作
- 数据安全
  - 数据分级加密
  - 用户细粒度权限管理
- 资源和流量管理

**架构图**

![130.Architecture](04Modulepics/130.Architecture.png)

**易于使用**

- 符合用户使用习惯
- 支持目前各类BI工具
- 提供JDBC/ODBC标准接口
  - 开源的JDBC和开发的多操作系统ODBC
- 记录用户的查询历史
  - QueryLog
- 提供全新的作业历史服务器
  - ViewPoint
  - Seesion粒度

**Zeta: 分析查询工具**

- 数据工程师用来开发新的数据管道
- 数据分析师用来探索大型数据集和即席查询
- 数据科学家从事机器学习的特征工程部分

![131.easyUse](04Modulepics/131.easyUse.png)

![132.easyUse](04Modulepics/132.easyUse.png)

![133.easyUse](04Modulepics/133.easyUse.png)

![134.EasyUse](04Modulepics/134.EasyUse.png)

![135.EasyUse](04Modulepics/135.EasyUse.png)

![136.EasyUse](04Modulepics/136.EasyUse.png)

![137.EasyUse](04Modulepics/137.EasyUse.png)

![138.EasyUse](04Modulepics/138.EasyUse.png)

![139.EasyUse](04Modulepics/139.EasyUse.png)

![140.EasyUse](04Modulepics/140.EasyUse.png)

## 查询优化

- Spark Driver优化
- Bucketing优化
- Range Partition优化
- File Index优化
- Relation Cache优化
- Query Rewrite优化
- Catalyst Rule增强

- Spark Driver优化
  - 修改调度器，提高并发，提高吞吐
  - 大查询Spill到磁盘
  - Thriftserver和Driver内存泄露
  - 表元信息缓存，计划缓存，广播缓存
- Range Partition优化
- File Index优化
- Relation Cache优化
- Query Rewrite优化
- Catalyst Rule增强

- Spark Driver优化
- Bucketing优化
  - 一个Bucket一个文件
  - Bucket列默认有序
  - Join keys是Bucket keys的子集
  - 部分排序的RDD，将排序下推到Scan时
  - 支持rebucketing提高并发
- Range Partition优化
- File Index优化
- Relation Cache优化
- Query Rewrite优化
- Catalyst Rule增强

![141.QueryOptimization](04Modulepics/141.QueryOptimization.png)

- Spark Driver优化
- Bucketing优化
- Range Partition + Bucket优化
  - 减少小文件

![142.QueryOptimization](04Modulepics/142.QueryOptimization.png)

- File Index优化
- Relation Cache优化
- Query Rewrite优化
- Catalyst Rule增强

```sql
create ebay_range.dw_lstg_item
PARTITIONED BY RANGE (AUCT_END_DT DATE)
(
PARTITION p_20050101 VALUES LESS THAN ('2005-01-01'),
PARTITION p_20060101 VALUES LESS THAN ('2006-01-01'),
PARTITION p_20070101 VALUES LESS THAN ('2007-01-01'),
PARTITION p_20080101 VALUES LESS THAN ('2008-01-01'),
PARTITION p_20090101 VALUES LESS THAN ('2009-01-01'),
PARTITION p_20100101 VALUES LESS THAN ('2010-01-01'),
PARTITION p_20110101 VALUES LESS THAN ('2011-01-01'),
PARTITION p_20120101 VALUES LESS THAN ('2012-01-01'),
PARTITION p_20130101 VALUES LESS THAN ('2013-01-01'),
PARTITION p_20140101 VALUES LESS THAN ('2014-01-01'),
PARTITION p_20150101 VALUES LESS THAN ('2015-01-01'),
PARTITION p_20160101 VALUES LESS THAN ('2016-01-01'),
PARTITION p_20170101 VALUES LESS THAN ('2017-01-01'),
PARTITION p_20180101 VALUES LESS THAN ('2018-01-01'),
PARTITION p_20190101 VALUES LESS THAN ('2019-01-01'),
PARTITION p_20200101 VALUES LESS THAN ('2020-01-01'),
PARTITION p_99991231 VALUES LESS THAN ('9999-12-31')
)
CLUSTERED BY (ITEM_ID)
SORTED BY (ITEM_ID, AUCT_END_DT)
INTO 1000 BUCKETS AS
select * from access_views.dw_lstg_item;
```

- Spark Driver优化
- Bucketing优化
- Range Partition优化
- File Index优化
  - BloomingFilter索引
  - Parquet row group

![143.QueryOptimization](04Modulepics/143.QueryOptimization.png)

- Relation Cache优化
- Query Rewrite优化
- Catalyst Rule增强

- Spark Driver优化
- Bucketing优化
- Range Partition优化
- File Index优化
- Relation Cache优化
  - 缓存远程热点表到本地SSD
  - 同语句表元数据缓存
  - 跨session的Hive元数据缓存
- Query Rewrite优化
- Catalyst Rule增强

![144.QueryOptimization](04Modulepics/144.QueryOptimization.png)

- Spark Driver优化
- Bucketing优化
- Range Partition优化
- File Index优化
- Relation Cache优化
- Query Rewrite优化
  - 物化视图自动重写

![145.QueryOptimization](04Modulepics/145.QueryOptimization.png)

- Catalyst Rule增强
- 支持临时表
- Limit优化
- 多线程Scan算子
- DPP和AE的结合
- Shuffle内存优化
- Shuffle fetch优化
- 自动小文件合并
- 惰性Listing支持
- Hive操作拆分读写锁
- Zombie任务优化
- 新一代CBO

**AQE**

- 支持多表Skew Join
- 支持带Union的Skew Join
- 优化NAAJ（Null-Aware-Anti-Join）
- 优化CTAS和Insert
- Join膨胀率检测
- 支持部分提交任务
- 支持Join下推

**语法兼容**

- Teradata UDF
- UPDATE/DELETE/MERGE
- QUARLITY

**数据安全**

- Parquet文件footer加密
- Impersonation
- SQL访问控制
- 列级数据加解密
- 系统审计
- 和TD相同的Access Bundle

![146.DataSecurity](04Modulepics/146.DataSecurity.png)

**资源和流程管理**

- 通过Gateway进队列管理
- Spark Thrift Servers on Yarn
- 支持多级用户认证
- 支持Impersonation
- 自动化session分发
- 多维度监控和告警
- 系统审计记录

![147.ResourceManager](04Modulepics/147.ResourceManager.png)

**Spark 2.0的主要问题**

- 一成不变的执行计划缺少更多优化的可能
- 最大化的提高不同数据源的吞吐
- 缺乏基本的数仓管理功能
- 大规模数据科学支持

# Spark 3.0

**Spark 3.0做了什么？**

![148.Spark3.0](04Modulepics/148.Spark3.0.png)

**DataSource V2**

- 可插拔的Catalog
- 强化Pushdown
- 统一批流一体API

**Spark的成功能让我们学到**

- 核心问题
- 灵活架构
- 强易用性
- 构建生态
- 拥抱云服务
- 未雨绸缪

**References**
https://www.jianshu.com/p/b719c6415411
https://blog.csdn.net/qq_41775852/article/details/105471662

